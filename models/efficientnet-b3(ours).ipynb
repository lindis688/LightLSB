{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":34595,"sourceType":"datasetVersion","datasetId":26922},{"sourceId":7127488,"sourceType":"datasetVersion","datasetId":4111785},{"sourceId":7128826,"sourceType":"datasetVersion","datasetId":4112738},{"sourceId":7162113,"sourceType":"datasetVersion","datasetId":4136874},{"sourceId":7201909,"sourceType":"datasetVersion","datasetId":4166007},{"sourceId":7214564,"sourceType":"datasetVersion","datasetId":4174861}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from fastai.vision.all import *\nimport torchvision\npath=Path(\"/kaggle/input/zy-www-lbq-224\")# 基于新滤波器的无扩展有意义加密\nfiles=get_image_files(path)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SiameseImage(fastuple):\n    def show(self, ctx=None, **kwargs): \n        img1,img2,same_breed = self\n        if not isinstance(img1, Tensor):\n            if img2.size != img1.size: img2 = img2.resize(img1.size)\n            t1,t2 = tensor(img1),tensor(img2)\n            t1,t2 = t1.permute(2,0,1),t2.permute(2,0,1)\n        else: t1,t2 = img1,img2\n        line = t1.new_zeros(t1.shape[0], t1.shape[1], 10)\n        return show_image(torch.cat([t1,line,t2], dim=2), \n                          title=same_breed, ctx=ctx)\nclass SiameseTransform(Transform):\n    def __init__(self, files, label_func, splits):\n        self.labels = files.map(label_func).unique()\n        self.lbl2files = {l: L(get_image_files(path/l)) for l in self.labels}\n        self.label_func = label_func\n        self.valid = {f: self._draw(f) for f in files[splits[1]]}\n        \n    def encodes(self, f):\n        f2,t = self.valid.get(f, self._draw(f))\n        img1,img2 = PILImage.create(f),PILImage.create(f2)\n        return SiameseImage(img1, img2, t)\n    \n    def _draw(self, f):\n        same = random.random() < 0.5\n        cls = self.label_func(f)\n        if not same: cls = random.choice(L(l for l in self.labels if l != cls)) \n        return random.choice(self.lbl2files[cls]),same\n    \nsplits = RandomSplitter()(files)\ntfm = SiameseTransform(files, parent_label, splits)\ntls = TfmdLists(files, tfm, splits=splits)\n\ndef halftone(img):\n    if isinstance(img, PILImage):\n        img1=img.convert(\"1\").convert(\"L\")\n        return img1\n    else:\n        return img\n\ndls = tls.dataloaders(after_item=[Resize(224), ToTensor], \n    after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)],\n                     bs=4) # CUDA out of memory\n#*aug_transforms()\nclass SiameseModel(Module):\n    def __init__(self, encoder, head):\n        self.encoder,self.head = encoder,head\n    def forward(self, x1, x2):\n        x1 = self.encoder(x1)\n        x2 = self.encoder(x2)\n        x1 = self.head(x1)\n        x2 = self.head(x2)\n        return x1, x2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@typedispatch\ndef show_batch(x:SiameseImage, y, samples, ctxs=None, max_n=6, nrows=None, ncols=2, figsize=None, **kwargs):\n    if figsize is None: figsize = (ncols*6, max_n//ncols * 3)\n    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), nrows=None, ncols=ncols, figsize=figsize)\n    for i,ctx in enumerate(ctxs): SiameseImage(x[0][i], x[1][i], ['Not similar','Similar'][x[2][i].item()]).show(ctx=ctx)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dls.show_batch()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nencoder = create_body(efficientnet_b3(pretrained=True), cut=-2)\nhead = create_head(1536, 128, [512, 256], 0.5, bn_final=True)\nmodel = SiameseModel(encoder, head)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from fastai.optimizer import Adam\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n\n    def forward(self, ops, target, size_average=True):\n        op1, op2 = ops[0], ops[1]\n        dist = F.pairwise_distance(op1, op2)\n        pdist = dist * target\n        ndist = dist * (~target)\n        loss = 0.5 * ((pdist**2) + (F.relu(self.margin - ndist)**2))\n        loss = loss.mean() if size_average else loss.sum()\n        return loss\n\ndef siamese_splitter(model):\n    return [params(model.encoder), params(model.head)]\n           \n\ndef contrastive_accuracy(ops, targets):\n    op1, op2 = ops[0], ops[1]\n    dists = F.pairwise_distance(op1, op2)\n    optimal_threshold.find(dists, targets)\n    preds = (dists < optimal_threshold.best_threshold).float()\n    return (preds == targets).float().mean()\n\ndef accuracy(ops, targets):\n    op1, op2 = ops[0], ops[1]\n    dists = F.pairwise_distance(op1, op2)\n    optimal_threshold.find(dists, targets)\n    preds = (dists < optimal_threshold.best_threshold)\n\n    true_positives = torch.sum((preds == 1) & (targets == 1)).item()\n    true_negatives = torch.sum((preds == 0) & (targets == 0)).item()\n    false_positives = torch.sum((preds == 1) & (targets == 0)).item()\n    false_negatives = torch.sum((preds == 0) & (targets == 1)).item()\n\n    accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives) if (true_positives + true_negatives + false_positives + false_negatives) > 0 else 0.0\n\n    return accuracy\n\ndef precision(ops, targets):\n    op1, op2 = ops[0], ops[1]\n    dists = F.pairwise_distance(op1, op2)\n    optimal_threshold.find(dists, targets)\n    preds = (dists < optimal_threshold.best_threshold)\n\n    true_positives = torch.sum((preds == 1) & (targets == 1)).item()\n    false_positives = torch.sum((preds == 1) & (targets == 0)).item()\n\n    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n\n    return precision\n\ndef recall(ops, targets):\n    op1, op2 = ops[0], ops[1]\n    dists = F.pairwise_distance(op1, op2)\n    optimal_threshold.find(dists, targets)\n    preds = (dists < optimal_threshold.best_threshold)\n\n    true_positives = torch.sum((preds == 1) & (targets == 1)).item()\n    false_negatives = torch.sum((preds == 0) & (targets == 1)).item()\n\n    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n\n    return recall\n\ndef f1_score(ops, targets):\n    op1, op2 = ops[0], ops[1]\n    dists = F.pairwise_distance(op1, op2)\n    optimal_threshold.find(dists, targets)\n    preds = (dists < optimal_threshold.best_threshold)\n\n    true_positives = torch.sum((preds == 1) & (targets == 1)).item()\n    false_positives = torch.sum((preds == 1) & (targets == 0)).item()\n    false_negatives = torch.sum((preds == 0) & (targets == 1)).item()\n\n    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0.0\n    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0.0\n\n    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n\n    return f1_score\n\nclass OptimalThreshold:\n    def __init__(self, start=0.1, end=4.0, step=0.01):\n        self.start = start\n        self.end = end\n        self.step = step\n        self.best_threshold = None\n\n    def find(self, preds, targets):\n        best_accuracy = 0.0\n        for threshold in np.arange(self.start, self.end, self.step):\n            preds_thresholded = (preds < threshold).float()\n            accuracy = (preds_thresholded == targets).float().mean()\n            if accuracy > best_accuracy:\n                best_accuracy = accuracy\n                self.best_threshold = threshold\n                \nclass PrintBestThreshold(Callback):\n    def after_epoch(self):\n        print(f\"Epoch {self.learn.epoch} LR:{self.opt.hypers[0]['lr']:.10f} Best threshold: {optimal_threshold.best_threshold:.2f}\")\n\noptimal_threshold = OptimalThreshold()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = Learner(dls, model, loss_func=ContrastiveLoss(margin=5.0), opt_func=Adam,\n                splitter=siamese_splitter, metrics=[accuracy, precision, recall, f1_score],cbs=PrintBestThreshold())\nlearn.lr_find()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.freeze()\nlearn.fit_one_cycle(15, 1e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(15, slice(1e-5,1e-3))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.save('efficientnet_b3_zy_www_lbq_224')","metadata":{},"execution_count":null,"outputs":[]}]}